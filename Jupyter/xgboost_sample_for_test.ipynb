{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "u1M7_qBcwcQV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZhVuuGuwgCl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready\n"
     ]
    }
   ],
   "source": [
    "# Download & unzip the dataset, unless it's already present\n",
    "from pathlib import Path\n",
    "\n",
    "url = 'https://www.vs.inf.ethz.ch/edu/HS2019/SE/xXjxkLul5TDrlSbniZFaIUu1gKUjZ2qj/example_data.zip'\n",
    "\n",
    "if not Path(\"./example_data\").is_dir():\n",
    "  if not Path(\"./example_data.zip\").is_file():\n",
    "    !pip install wget\n",
    "    import wget\n",
    "    wget.download(url,'./example_data.zip')\n",
    "  from zipfile import ZipFile\n",
    "  ZipFile('example_data.zip','r').extractall()\n",
    "print('Data ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IphfrEXgwcQW",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomma\\anaconda2\\envs\\python3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:466: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            end    id   mode         start  \\\n",
      "0  1.558109e+12  88.0  605.0  1.558108e+12   \n",
      "\n",
      "                                   user  \n",
      "0  408483c0-4287-456d-a35c-b14e28ce10ec  \n",
      "   acc  leg       reading                                  user        x  \\\n",
      "0    3   88  1.558108e+12  408483c0-4287-456d-a35c-b14e28ce10ec  0.00639   \n",
      "\n",
      "          y         z  \n",
      "0  0.030259  0.008629  \n",
      "   acc         alt  bearing        lat  leg       lng       reading  speed  \\\n",
      "0  3.0  492.416046        0  47.324327   88  8.530802  1.558108e+12    0.0   \n",
      "\n",
      "                                   user  \n",
      "0  408483c0-4287-456d-a35c-b14e28ce10ec  \n"
     ]
    }
   ],
   "source": [
    "# Read data into Python\n",
    "\n",
    "# Pandas is a popular library for managing and analysing data in Python.\n",
    "# Google's course on Machine Learning has a short intro:\n",
    "# See https://colab.research.google.com/notebooks/mlcc/intro_to_pandas.ipynb\n",
    "import pandas as pd\n",
    "\n",
    "directory = 'example_data'\n",
    "\n",
    "legs_df = pd.read_csv(directory + '/legs.csv', index_col=0)\n",
    "acc_readings = pd.read_csv(directory + '/acc_readings.csv', index_col=0)\n",
    "locations_scans = pd.read_csv(directory + '/locations_scans.csv', index_col=0)\n",
    "bluetooth_scans = pd.read_csv(directory + '/bluetooth_scans.csv', index_col=0)\n",
    "wifi_scans = pd.read_csv(directory + '/wifi_scans.csv', index_col=0)\n",
    "gyro_readings = pd.read_csv(directory + '/gyro_readings.csv', index_col=0)\n",
    "\n",
    "\n",
    "# Print the first row of each file (quick sanity check)\n",
    "print(legs_df.head(1))\n",
    "print(acc_readings.head(1))\n",
    "print(locations_scans.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KsXhb_DwwcQY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Calculate windows and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUXpW0NrwcQY",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 88.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 89.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 90.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 91.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 92.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 93.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 94.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 95.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 96.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 97.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 98.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 99.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 100.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 101.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 102.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 103.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 104.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 105.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 106.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 107.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 108.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 109.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 110.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 111.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 120.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 121.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 122.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 124.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 125.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 126.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 127.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 128.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 129.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 130.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 132.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 134.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 135.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 136.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 140.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 141.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 142.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 143.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 144.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 145.0\n",
      "windowing 408483c0-4287-456d-a35c-b14e28ce10ec 146.0\n"
     ]
    }
   ],
   "source": [
    "# Split data into windows for further processing\n",
    "\n",
    "# NumPy is a popular library for fast numerical computations with large arrays and matrices.\n",
    "# At https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.00-Introduction-to-NumPy.ipynb\n",
    "# you can find an introduction to NumPy (Click on \"Understanding Data Types in Python >\" for the next page)\n",
    "import numpy as np\n",
    "\n",
    "#window size in ms\n",
    "window_size = 10000\n",
    "\n",
    "# dataframe containing the features.\n",
    "# Columns: mean acceleration, max speed, transportation mode (target variable)\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "# iterate over all legs\n",
    "for index, row in legs_df.iterrows():\n",
    "    print('windowing', row['user'], row['id'])\n",
    "    boundary_left = row['start']\n",
    "    boundary_right = boundary_left + window_size\n",
    "    previous_bluetooth = 0\n",
    "    previous_wifi = 0\n",
    "    \n",
    "    while boundary_right < row['end']:\n",
    "        features = {}\n",
    "        \n",
    "        \n",
    "        # get accelerometer readings within window\n",
    "        acc_readings_in_window = acc_readings.loc[\n",
    "                (acc_readings['leg'] == row['id']) &\n",
    "                (acc_readings['user'] == row['user']) &\n",
    "                (acc_readings['reading'] > boundary_left) &\n",
    "                (acc_readings['reading'] <= boundary_right)\n",
    "            ].copy()\n",
    "        \n",
    "        # calculate magnitude\n",
    "        acc_readings_in_window['magnitude'] = np.linalg.norm(acc_readings_in_window[['x','y','z']].values,axis=1)\n",
    "        \n",
    "        # save mean magnitude as feature\n",
    "        features['acc_mean'] = acc_readings_in_window['magnitude'].mean()\n",
    "        features['acc_x'] = acc_readings_in_window['x'].mean()\n",
    "        features['acc_y'] = acc_readings_in_window['y'].mean()\n",
    "        features['acc_z'] = acc_readings_in_window['z'].mean()\n",
    "        \n",
    "        \n",
    "        # get location scans within window\n",
    "        locations_scans_in_window = locations_scans.loc[\n",
    "                (locations_scans['leg'] == row['id']) &\n",
    "                (locations_scans['user'] == row['user']) &\n",
    "                (locations_scans['reading'] > boundary_left) &\n",
    "                (locations_scans['reading'] <= boundary_right)\n",
    "            ].copy()\n",
    "        \n",
    "        # save max speed as feature\n",
    "        features['max_speed'] = locations_scans_in_window['speed'].max()\n",
    "        features['min_speed'] = locations_scans_in_window['speed'].min()\n",
    "        features['mean_speed'] = locations_scans_in_window['speed'].mean()\n",
    "        \n",
    "        \n",
    "        # Get Bluetooth\n",
    "        bluetooth_scans_in_window = bluetooth_scans.loc[\n",
    "                (bluetooth_scans['leg'] == row['id']) &\n",
    "                (bluetooth_scans['user'] == row['user']) &\n",
    "                (bluetooth_scans['reading_time'] > boundary_left) &\n",
    "                (bluetooth_scans['reading_time'] <= boundary_right)\n",
    "            ].copy()\n",
    "    \n",
    "        # Unique Bluetooth devices\n",
    "        if (len(bluetooth_scans_in_window.mac) == 0): \n",
    "            if (bluetooth_scans_in_window['mac'].nunique() != 0):\n",
    "                features['bluetooth_numbers'] = bluetooth_scans_in_window['mac'].nunique()\n",
    "                previous_bluetooth = bluetooth_scans_in_window['mac'].nunique()\n",
    "            else:\n",
    "                features['bluetooth_numbers'] = previous_bluetooth \n",
    "        else:\n",
    "            features['bluetooth_numbers'] = bluetooth_scans_in_window['mac'].nunique()\n",
    "            previous_bluetooth = bluetooth_scans_in_window['mac'].nunique()\n",
    "            \n",
    "        \n",
    "        # WIFI\n",
    "        '''wifi_scans_in_window = wifi_scans.loc[\n",
    "                (wifi_scans['leg'] == row['id']) &\n",
    "                (wifi_scans['user'] == row['user']) &\n",
    "                (wifi_scans['reading_time'] > boundary_left) &\n",
    "                (wifi_scans['reading_time'] <= boundary_right)\n",
    "            ].copy()\n",
    "        \n",
    "        if (len(wifi_scans_in_window.bssid) == 0):   \n",
    "            print(\"EMPTY\")\n",
    "            if (wifi_scans_in_window['bssid'].nunique() != 0):\n",
    "                features['wifi_numbers'] = wifi_scans_in_window['bssid'].nunique()\n",
    "                previous_wifi = wifi_scans_in_window['bssid'].nunique()\n",
    "                print(wifi_scans_in_window['bssid'].nunique())\n",
    "            else:\n",
    "                features['wifi_numbers'] = previous_wifi  \n",
    "                print(previous_wifi)\n",
    "        else:\n",
    "            print(\"NOT EMPTY\")\n",
    "            features['wifi_numbers'] = wifi_scans_in_window['bssid'].nunique()\n",
    "            previous_wifi = wifi_scans_in_window['bssid'].nunique()\n",
    "            print(wifi_scans_in_window['bssid'].nunique())'''\n",
    "                        \n",
    "        \n",
    "        #Get Gyro\n",
    "        gyro_readings_in_window = gyro_readings.loc[\n",
    "                (gyro_readings['leg'] == row['id']) &\n",
    "                (gyro_readings['user'] == row['user']) &\n",
    "                (gyro_readings['reading'] > boundary_left) &\n",
    "                (gyro_readings['reading'] <= boundary_right)\n",
    "            ].copy()\n",
    "        \n",
    "        # calculate magnitude\n",
    "        gyro_readings_in_window['magnitude'] = np.linalg.norm(gyro_readings_in_window[['x','y','z']].values,axis=1)\n",
    "        \n",
    "        # save mean magnitude as feature\n",
    "        features['gyro_mean'] = gyro_readings_in_window['magnitude'].mean()\n",
    "        features['gyro_x'] = gyro_readings_in_window['x'].mean()\n",
    "        features['gyro_y'] = gyro_readings_in_window['y'].mean()\n",
    "        features['gyro_z'] = gyro_readings_in_window['z'].mean()\n",
    "        \n",
    "        \n",
    "        # save user, leg and transportation mode\n",
    "        features['user'] = row['user']\n",
    "        features['leg'] = row['id']\n",
    "        features['mode'] = row['mode']\n",
    "        \n",
    "        # save features in features data frame\n",
    "        features_df = features_df.append(features, ignore_index=True)\n",
    "        \n",
    "        # set new boundaries\n",
    "        boundary_left = boundary_right\n",
    "        boundary_right = boundary_left + window_size\n",
    "        \n",
    "print('Feature calculation done')\n",
    "print(features_df.head())\n",
    "\n",
    "features_df.to_csv(\"window_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DflJCllEwcQa"
   },
   "source": [
    "# Shuffle split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NcSBZ355wcQa",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly split data into training and test set\n",
    "\n",
    "# Scikit-Learn is a popular library for common machine learning algorithms.\n",
    "# Here, it is used only for its support for efficiently splitting a dataset.\n",
    "# For more information, see https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.02-Introducing-Scikit-Learn.ipynb\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "y = np.array(features_df['mode'])\n",
    "X = np.array(features_df.drop(['user', 'leg', 'mode'], axis=1))\n",
    "X = np.nan_to_num(X)\n",
    "\n",
    "features_df2 = features_df.drop(['user', 'leg', 'mode'], axis=1)\n",
    "features_df2.to_excel(\"Results/testn.xlsx\")\n",
    "\n",
    "shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "train_indices, test_indices = next(shuffle_split.split(X=X, y=y))\n",
    "\n",
    "X_train, X_test = X[train_indices], X[test_indices]\n",
    "y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "print('Shape of X_train', X_train.shape)\n",
    "print('Shape of y_train', y_train.shape)\n",
    "print('Shape of X_test', X_test.shape)\n",
    "print('Shape of y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nK-wgH9HwcQc"
   },
   "source": [
    "# Train XGBoost on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzON3v_kwcQc",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train Gradient Boosted Decisions Trees\n",
    "\n",
    "#XGBoost implements the\"Extreme Gradient Boosting\" algorithm.\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(n_jobs=-1, objective='multi:softprob', random_state=42)\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHAh8ppdwcQe"
   },
   "source": [
    "# Make classifications on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Mih0n5zwcQe",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "print('Shape of y_pred', y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSUDPtu5wcQf"
   },
   "source": [
    "# Print classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2a3eZdqwcQg",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# confusion matrix\n",
    "confMatrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(confMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-D9Rd820wcQh"
   },
   "source": [
    "# Train model on whole set and export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8wqxt3MwcQi",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb_classifier.fit(X, y)\n",
    "print('xgboost.model')\n",
    "xgb_classifier.save_model('xgboost_model_test')\n",
    "print('model exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "df = pd.read_csv('window.csv', index_col=False)\n",
    "df.to_excel(\"Results/acc_mean.xlsx\")\n",
    "\n",
    "df.loc[df['mode'] == 2.0]\n",
    "print(df.head())\n",
    "df_acc_mean = df[['acc_mean', 'mode']]\n",
    "df_acc_mean.loc[df_acc_mean['mode'] == '2.0']\n",
    "df_acc_mean.dropna(axis=1)\n",
    "\n",
    "print(df_acc_mean['acc_mean'].mean())\n",
    "\n",
    "\n",
    "#df.loc[df['acc_mean'] == some_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "xgboost_sample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
